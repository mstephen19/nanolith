# Nanolith

Multithreading in minutes. _(More intuitive and feature-rich than [piscina](https://www.npmjs.com/package/piscina)!)_

[![TypeScript](https://badgen.net/badge/-/TypeScript/blue?icon=typescript&label)](https://www.typescriptlang.org/) [![CircleCI](https://circleci.com/gh/mstephen19/nanolith.svg?style=svg)](https://app.circleci.com/pipelines/github/mstephen19/nanolith) [![Install size](https://packagephobia.com/badge?p=nanolith@latest)](https://packagephobia.com/result?p=nanolith@latest)

[![Version](https://img.shields.io/npm/v/nanolith?color=blue)](https://github.com/mstephen19/nanolith/releases) ![Weekly downloads](https://img.shields.io/npm/dw/nanolith?color=violet) ![Libraries.io dependency status](https://img.shields.io/librariesio/release/npm/nanolith) [![GitHub issues](https://img.shields.io/github/issues/mstephen19/nanolith?color=red)](https://github.com/mstephen19/nanolith/issues)

<center>
    <img src="https://user-images.githubusercontent.com/87805115/199340985-d76cc3ea-6abb-4a4e-ac1b-a95fc693947f.png" width="550">
</center>

## ‚ùî About

‚ú®**Nanolith**‚ú® is a performant, reliable, easy-to-use, and well-documented multithreading library. It serves to not only build upon, but entirely replace the _(deprecated)_ [Threadz](https://github.com/mstephen19/threadz) library.

There have always been three main goals for Nanolith:

1. Performance üèÉ
2. Ease-of-use üòá
3. Seamless TypeScript support üòé

### So what can you do with it?

Here's a quick rundown of everything you can do in Nanolith:

- Offload expensive tasks to separate threads.
- Spawn up separate-threaded "nanoservices" that can run any tasks you want.
- Communicate back and forth between threads by sending messages.
- Stream data between threads with the already familiar [`node:stream`](https://nodejs.org/api/stream.html) API.
- Share memory between threads using the familiar-feeling `SharedMap` class.

## üìñ Table of contents

- [‚ùî About](#-about)
- [üíæ Installation](#-installation)
- [üìù Defining your tasks](#-defining-your-tasks)
  - [`define()` options](#define-options)
- [üë∑ Running a task](#-running-a-task)
  - [Task function options](#task-function-options)
- [üé© Understanding services](#-understanding-services)
  - [`launchService()` options](#launchservice-options)
- [üé¨ Coordinating services](#-coordinating-services)
- [ü™ù Hooks](#-hooks)
- [üö® Managing concurrency](#-managing-concurrency)
- [üì® Communicating between threads](#-communicating-between-threads)
- [üì° Streaming data between threads](#-streaming-data-between-threads)
- [üíæ Sharing memory between threads](#-sharing-memory-between-threads)
- [üßë‚Äçüè´ Examples](#-examples)
- [üìú License](#-license)

## üíæ Installation

The latest version can be installed via any package manager of your choice.

```shell
npm install nanolith@latest
# or
yarn add nanolith@latest
```

Beta versions are released under the **next** tag and can be installed like this:

```shell
npm install nanolith@next
# or
yarn add nanolith@next
```

## üìù Defining your tasks

A **task** is any function that **you** define which is accessible by Nanolith's APIs. Tasks can be defined using the `define()` function in a separate file dedicated to definitions.

```TypeScript
// worker.ts üíº
import { define } from 'nanolith';

// Exporting the variable is not a requirement, but it is
// necessary to somehow export the resolved value of the
// function in order to have access to it later on.
export const worker = await define({
    add(x: number, y: number) {
        return x + y;
    },
    async waitThenAdd(x: number, y: number) {
        await new Promise((resolve) => setTimeout(resolve, 5e3))
        return x + y;
    },
    // Functions don't have to be directly defined within the
    // object, they can be defined elsewhere outside, or even
    // imported from a totally different module.
    subtract,
});

function subtract(x: number, y: number) {
    return x - y;
};
```

By passing functions into `define()`, you immediately turn them into multithreadable **tasks**. No further configuration is required.

### `define()` options

As seen above, the first argument to `define()` is an object containing your functions. The second parameter is an object accepting the following _(optional)_ configurations:

| Name | Type | About |
|-|-|-|
| `file` | **string** | If `define()`'s file location detection is not working correctly, the true file location for the set of definitions can be provided here. |
| `identifier` | **string** | A unique identifier for the set of definitions. Overrides the auto-identifier generated by Nanolith. |
| `safeMode` | **boolean** | Whether or not to prevent the usage of the returned **Nanolith** API from within the same file where their definitions were created. Defaults to `true`. |

## üë∑ Running a task

After [defining](#-defining-your-tasks) a set of tasks, you can import them and call them anywhere by directly using the **Nanolith** API resolved by the `define()` function. The only difference is that instead of being called on the main thread, a new thread will be created for the task and it will be run there.

```TypeScript
// üí° index.ts
// Importing the Nanolith API we created in worker.ts
import { worker } from './worker.js';

// Run the "add" function on a separate thread and wait
// for it to complete before moving forward.
const result = await worker({
    // Provide the name of the task.
    name: 'add',
    // Provide the parameters of the function.
    params: [2, 3],
});

// The result is sent back to the main thread
// and resolved by the task function call.
console.log(result); // -> 5
```

The new thread's process is shut down after the task finishes.

> **üìù Note:** Notice that even with the synchronous `add()` function, it is now asynchronous when being multithreaded.

### Task function options

`name` and `params` are amongst many of the possible options that can be passed in when running a task:

| Name | Type | About |
|-|-|-|
| `name` | **string** | The name of the task to call. Must be present on the set of definitions. |
| `params` | **any[]** | The arguments for the task in array form. |
| `priority` | **boolean** | Whether or not to treat the task's worker as priority over others when being queued into the `pool`. |
| `reffed` | **boolean** | When `true`, the underlying `Worker` instance is [reffed](https://nodejs.org/api/worker_threads.html#workerref). Defaults to `false`. |
| `messengers` | [**Messenger**](#-communicating-between-threads)**[]** | The `Messenger`s that should be accessible to the task. |
| `options` | **object** | An object containing _most_ of the options available on the [`Worker` constructor](https://nodejs.org/api/worker_threads.html#new-workerfilename-options). |

## üé© Understanding services

**Services** are Nanolith's flagship feature. Running a task on a service works similarly to [running a task](#-running-a-task) normally; however, the key difference is that the thread only shuts down when you tell it to. This means that you can run multiple tasks on the same thread rather than spawning up a new one for each call.

Considering the definitions we created [here](#-defining-your-tasks), here is how a service would be launched and a task would be called on it.

```TypeScript
// üí° index.ts
// Importing the Nanolith API we created in worker.ts
import { worker } from './worker.js';

// Spawn up a new thread that has access to all of
// our tasks.
const service = await worker.launchService();

// Command the service thread to run the "add" function.
const result = await service.call({
    name: 'waitThenAdd',
    params: [2, 3],
});

// We can run service.call() as many times as we want, and
// all those tasks will be called on the same thread...

// Similarly to regular task calls, the return value
// is sent back to the main thread and resolve by the call.
console.log(result);

// Shut down the second thread.
await service.close();
```

### `launchService()` options

The configurations for `Nanolith.launchService()` are nearly identical to the [task function options](#task-function-options) with the addition of `exceptionHandler`:

| Name | Type | About |
|-|-|-|
| `exceptionHandler` | **function** | An optional but _highly recommended_ option that allows you to catch uncaught exceptions within the service. |
| `priority` | **boolean** | Whether or not to treat the service's worker as priority over others when being queued into the `pool`. |
| `reffed` | **boolean** | When `true`, the underlying `Worker` instance is [reffed](https://nodejs.org/api/worker_threads.html#workerref). Defaults to `false`. |
| `messengers` | [**Messenger**](#-communicating-between-threads)**[]** | The `Messenger`s that should be accessible to the service. |
| `options` | **object** | An object containing _most_ of the options available on the [`Worker` constructor](https://nodejs.org/api/worker_threads.html#new-workerfilename-options). |

<!-- todo: Go over all methods & properties available on Service -->

## üé¨ Coordinating services

In a scalable application utilizing multiple identical [services](#launchservice-options), it is possible to optimize them by treating the main thread as an orchestrator and managing the workloads on each service. Nanolith's `ServiceCluster` automatically does this for you.

```TypeScript
// üí° index.ts
// Importing the Nanolith API we created in worker.ts
import { worker } from './worker.js';

// Launch 6 identical services at the same time.
// Returns a "ServiceCluster" instance.
const cluster = await worker.clusterize(6, {
    // These options will be applied to all of the 6
    // services being launched.
    exceptionHandler({ error, terminate }) {
        console.error(error);
    },
    priority: true;
});

// Use the least busy service on the cluster.
// This is the service that is currently running
// the least amount of task calls.
const service = cluster.use();

// Call the task on the service as you normally would.
const result = await service.call({
    name: 'subtract',
    params: [10, 5],
});

console.log(result);

// Close all services on the cluster.
await cluster.closeAll();
```

For simplicity of the above example, we are only running a single task. However, `ServiceCluster` can be used to run a large amount of heavy operations in true parallel on multiple services.

<!-- todo: Go over all methods & properties available on ServiceCluster -->

## ü™ù Hooks

For a bit of finer control over your services and tasks, three hooks are available and can be provided directly to [`define()`](#-defining-your-tasks).

```TypeScript
// worker.ts üíº
import { define } from 'nanolith';

export const worker = await define({
    // Runs before a service is launched and before the
    // "launchService" function resolves its promise.
    __initializeService(threadId) {
        console.log(`Initializing service on thread: ${threadId}`);
    },
    // Runs before a task is called.
    __beforeTask({ name, inService }) {
        console.log(`Running task ${name}.`);
        // You have access to "inService", which tells you if the
        // task will run standalone, or within a service.
        console.log(`${inService ? 'Is' : 'Is not'} in a service.`);
    },
    // Runs after a task is called.
    __afterTask({ name, inService }) {
        console.log(`Finished task ${name}`);
    },
    // Define your tasks here...
});
```

These hooks run on the same thread as their service/task.

## üö® Managing concurrency

Nanolith automatically manages the concurrency your services and task calls with the internal `pool` class. By default, the maximum concurrency is one thread per core on the machine. This is a safe value to go with; however, the `maxConcurrency` can be modified up using one of the set `ConcurrencyOption`s.

```TypeScript
// index.ts üí°
// Importing the pool
import { pool, ConcurrencyOption } from 'nanolith';

// One thread per four cores.
pool.setConcurrency(ConcurrencyOption.Quarter);
// One thread per two cores.
pool.setConcurrency(ConcurrencyOption.Half);
// Default concurrency. One thread per core (x1).
pool.setConcurrency(ConcurrencyOption.Default);
// One thread per core.
pool.setConcurrency(ConcurrencyOption.x1);
// Two threads per core.
pool.setConcurrency(ConcurrencyOption.x2);
// Four threads per core.
pool.setConcurrency(ConcurrencyOption.x4);
// Six threads per core.
pool.setConcurrency(ConcurrencyOption.x6);
// Eight threads per core.
pool.setConcurrency(ConcurrencyOption.x8);
// Ten threads per core.
// Warning: This is overkill.
pool.setConcurrency(ConcurrencyOption.x10);
```

<!-- todo: go over the various other properties and methods on the pool -->

## üì® Communicating between threads

## üì° Streaming data between threads

<!-- Discuss using the streaming API on parent, Messenger, or Service -->

## üíæ Sharing memory between threads

<!-- SharedMap -->
<!-- Doing highly concurrent parallel operations with SharedMap -->

## üßë‚Äçüè´ Examples

## üìú License

The MIT License (MIT)

Copyright (c) 2022 Matthias Stephens

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
